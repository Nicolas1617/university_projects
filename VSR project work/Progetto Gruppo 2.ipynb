{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf2d92b-1e5c-40c0-bcc1-056280a70453",
   "metadata": {},
   "source": [
    "# Progetto Gruppo 2\n",
    "## Segmentazione di Cellule del sangue\n",
    "\n",
    "**Autori:** Fortunato Michela, Iodice Luisa, Minervini Nicolas, Modano Armando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43945e3-23d5-43b5-9f18-e90ac7c75b5e",
   "metadata": {},
   "source": [
    "# Fase preliminare\n",
    "Installiamo easy-cv-dataset che ci servirà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f7ad3-12ef-4138-a6ad-8ee18bd150a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/davin11/easy-cv-dataset keras-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8a6b2-10a3-4db6-927a-cae8a66dee5c",
   "metadata": {},
   "source": [
    "Scarichiamo ed estraiamo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44bdcf-2af8-4e11-867a-0702e998f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --user=corso --password=corso2025f https://www.grip.unina.it/download/corso/bbbc041seg-DatasetNinja.tar\n",
    "!tar --skip-old-files -xf bbbc041seg-DatasetNinja.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b066567-0b08-4b11-9367-b75c24fa02da",
   "metadata": {},
   "source": [
    "Scarichiamo lo script \"create-msk.py\" per la creazione delle maschere<br>\n",
    "Per evitare di dover importate manualmente ogni volta lo script \"create_msk.py\" è stato caricato su un GitHub personale e si scarica direttamente da lì<br>\n",
    "Creiamo anche le maschere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ad60e-5dea-499d-b12b-c250695114ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE = \"https://raw.githubusercontent.com/Nicolas1617/university_projects/refs/heads/main/VSR%20project%20work\"\n",
    "!wget -nc {SITE}/create_msk.py\n",
    "!python create_msk.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25d6687-4704-42bb-917d-81828f7b57c6",
   "metadata": {},
   "source": [
    "# Import di base\n",
    "Come prima cosa puliamo le variabili e importiamo le librerie che sicuramente ci serviranno, altre librerie le importeremo man mano all'occorrenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb7391-81e6-4bbc-93a1-5b4efcb0061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import keras\n",
    "import keras_hub\n",
    "import easy_cv_dataset as ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be65e77-d76f-448d-aa60-36adfcb02688",
   "metadata": {},
   "source": [
    "# Creazione delle tabelle di train e test\n",
    "Di seguito creiamo le tabelle per i dati di train e di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa5cf4-306b-4a63-b304-9e2c330334b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas\n",
    "list_train_img_path = [] #creiamo una lista vuota\n",
    "list_train_msk_path = glob('train/msk/*.png')\n",
    "for name in list_train_msk_path:\n",
    "    name=name[:-4] #il nome della maschera ha 4 caratteri in più per questo ci creiamo un nome con 4 caratteri in meno\n",
    "    name=name.replace('/msk/','/img/')\n",
    "    list_train_img_path.append(name)\n",
    "\n",
    "tab_train = pandas.DataFrame({'image': list_train_img_path,\n",
    "                        'segmentation_mask': list_train_msk_path})\n",
    "tab_train.to_csv('train_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58925041-eed1-4b18-9202-c31f06ce2337",
   "metadata": {},
   "source": [
    "Abbiamo visto che le immagini non erano tutte .png ma c'erano anche alcune .jpg, per questo motivo abbiamo creato il vettore **list_img_path** a partire dal vettore **list_msk_path**.\n",
    "Per farlo abbiamo confrontato i nomi delle immagini e delle maschere e abbiamo visto che i nomi delle maschere avevano 4 caratteri in più per questo motivo il vettore name prende tutti i caratteri tranne gli ultimi 4.\n",
    "Abbiamo seguito questa procedura e non preso anche i file .jpg dalla cartella img perché altrimenti non avremmo avuto la certezza che maschera e immagine corrispondessero\n",
    "Dato che siamo partiti dalla cartella delle maschere oltre ad accorciare il nome abbiamo dovuto sostituire la stringa **/msk/** con la stringa **/img/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd6af2-5861-4a39-8697-3f5afca77ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abbiamo stampato queste cose per capire come mai desse errore sulla lunghezza\n",
    "#print(len(list_img_path))\n",
    "#print(len(list_msk_path))\n",
    "#print(list_msk_path[0])\n",
    "#print(list_img_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63358c02-7014-452b-b0f3-410418f06876",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test_img_path = []\n",
    "list_test_msk_path = glob('test/msk/*.png')\n",
    "for name in list_test_msk_path:\n",
    "    name=name[:-4]\n",
    "    name=name.replace('/msk/','/img/')\n",
    "    list_test_img_path.append(name)\n",
    "\n",
    "tab_test = pandas.DataFrame({'image': list_test_img_path,\n",
    "                        'segmentation_mask': list_test_msk_path})\n",
    "tab_test.to_csv('test_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43e967-c94b-4256-90e1-21d262e7c320",
   "metadata": {},
   "source": [
    "# Creazione validation set\n",
    "Di seguito creiamo il validation set che sarà comporsto da 159 elementi presi in maniera causale dal train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8680485-7731-46b0-a6ab-21150496d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tab_tran, tab_valid = train_test_split(tab_train, test_size=159, random_state=34)\n",
    "tab_valid.to_csv('valid_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e40db0-6f0e-4b70-855c-8625f677397c",
   "metadata": {},
   "source": [
    "# [Augmentation](https://keras.io/api/layers/preprocessing_layers/image_augmentation/)\n",
    "Abbiamo deciso di fare operazioni random di variazione di luminosità, di rotazione e flip.<br>\n",
    "La variazione di luminosità va in un range -20%,+20%<br>\n",
    "La rotazione va da -5% di 360° a +5% di 360°<br>\n",
    "Il flip è fatto in orizzontale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b31fd-1125-4abe-bd4c-d3937eeea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "from keras.layers import Pipeline, RandomBrightness, RandomRotation, RandomFlip\n",
    "augmenter = Pipeline(layers=[\n",
    "    RandomBrightness(factor=(-0.2, 0.2), value_range=(0, 255)),\n",
    "    RandomRotation((-0.05,0.05)),\n",
    "    RandomFlip(\"horizontal\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a2a36",
   "metadata": {},
   "source": [
    "# Definizione del dataset\n",
    "Definiamo batch size, dimensione dell'immagine e dataset per train, validation e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d8632-0eb0-428c-9b0b-181e8be2db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "image_size = 512\n",
    "class_names = [\"Background\", \"Foreground\"]\n",
    "num_classes = 2\n",
    "from keras.layers import Resizing\n",
    "pre_batching_processing = Resizing(image_size, image_size)\n",
    "post_batching_processing = augmenter\n",
    "\n",
    "print('test-set')\n",
    "test_ds = ds.image_segmentation_dataset_from_dataframe(\n",
    "    'test_table.csv',\n",
    "    class_mode='categorical', class_names=class_names,\n",
    "    pre_batching_processing=pre_batching_processing,\n",
    "    shuffle=False, batch_size=batch_size) #nel test set non ha senso fare shuffle, ha senso solo nel training set\n",
    "\n",
    "print('trainig-set')\n",
    "train_ds = ds.image_segmentation_dataset_from_dataframe(\n",
    "    'train_table.csv',\n",
    "    class_mode='categorical', class_names=class_names,\n",
    "    pre_batching_processing=pre_batching_processing,\n",
    "    shuffle=True , batch_size=batch_size,\n",
    "    post_batching_processing=post_batching_processing)\n",
    "\n",
    "print('validation-set')\n",
    "valid_ds = ds.image_segmentation_dataset_from_dataframe(\n",
    "    'valid_table.csv',\n",
    "    class_mode='categorical', class_names=class_names,\n",
    "    pre_batching_processing=pre_batching_processing,\n",
    "    shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ff8f5-c505-4348-81f6-97b01abf0cb9",
   "metadata": {},
   "source": [
    "# Visualizzazione\n",
    "Di seguito visualizziamo un batch di immagini con la relativa mappa di segmentazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b3b08-4e5f-4000-bd7d-b8653ffc2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_cv_dataset.visualization import plot_segmentation_mask_gallery\n",
    "\n",
    "for images, segms in test_ds.take(1): # il for scorre solo sul primo batch\n",
    "    plot_segmentation_mask_gallery( # funzione per visualizzare image and box\n",
    "    images, y_true = segms, num_classes = num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a47ed-2c37-4086-bc1d-27dd9b9d9d74",
   "metadata": {},
   "source": [
    "# Importazione modello pre-addestrato\n",
    "[mit_b0_ade20k_512](https://www.kaggle.com/models/keras/mit/keras/mit_b0_ade20k_512/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c980a8-4ea6-44f3-b44c-bb1238357791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_hub.models import MiTBackbone, SegFormerBackbone\n",
    "from keras_hub.models import SegFormerImageSegmenter\n",
    "from keras_hub.models import ImageSegmenterPreprocessor as pre\n",
    "\n",
    "preprocessor = pre.from_preset(\"segformer_b0_ade20k_512\")\n",
    "encoder = MiTBackbone.from_preset(\"mit_b0_ade20k_512\",\n",
    "    load_weights=True,\n",
    "    image_shape=(image_size, image_size, 3),\n",
    ")\n",
    "backbone = SegFormerBackbone(\n",
    "    image_encoder=encoder,\n",
    "    projection_filters=256,\n",
    "    )\n",
    "model = SegFormerImageSegmenter(\n",
    "    preprocessor=preprocessor,\n",
    "    backbone=backbone,\n",
    "    num_classes=num_classes,\n",
    "    activation=None #abbiamo messo None perché in seguito mettiamo logit=True\n",
    "    )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa88621-694f-415b-84e1-9c90ec780324",
   "metadata": {},
   "source": [
    "# Train Backbone\n",
    "Conviene non bloccare il backbone ma riaddestrarlo perché il modello è pre addestrato su un dataset molto diverso dal nostro.<br>\n",
    "Abbiamo anche effettuato una prova con backbone bloccato e abbiamo visto un valore di circa 0.78 con backbone bloccato a fronte di un valore di circa 0.92 con backbone riaddestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520039c-bcd6-4efb-9ace-79ae5665b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.backbone.trainable = False\n",
    "#model.summary()\n",
    "#abbiamo deciso di addestrare anche il backbone come test e abbiamo visto che siamo passati da 0.78 a 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188de37-87b1-4156-81de-a919aecf0a5a",
   "metadata": {},
   "source": [
    "# Learning Rate variabile\n",
    "Ha senso usare uno schedule del learning rate in modo da avere una rete che segue più step\n",
    "- **Step 1** learning rate alto per un adattamento rapido\n",
    "- **Step 2** learning rate più basso per stabilizzazione\n",
    "- **Step 3** learning rate ancora più basso per finalizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca629f66-945f-472a-91eb-905206c51ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr = 0.001 #definiamo un learning rate (lr) di partenza\n",
    "from keras import optimizers\n",
    "\n",
    "lr_decay = optimizers.schedules.PiecewiseConstantDecay( #schedulatore del lr, serve per ridurre il lr secondo uno scheduling\n",
    "    boundaries=[5*len(train_ds), 10*len(train_ds)], #qui diciamo che deve ridurre dopo 5 epoche e dopo 10 epoche\n",
    "    values=[base_lr, 0.1 * base_lr, 0.01 * base_lr], #qui diciamo di quanto deve ridurre il lr\n",
    ")\n",
    "optimizer = optimizers.Nadam(\n",
    "    learning_rate=lr_decay, global_clipnorm=10.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dce1eb-3a86-4125-b8a2-ff164018cf58",
   "metadata": {},
   "source": [
    "# [Early Stop](https://keras.io/api/callbacks/early_stopping/)\n",
    "L'eraly stop è una tecnica che permette di fermare l'addestramento in base ad alcuni criteri stabiliti:\n",
    "- **monitor** indica il valore da monitorare, nel nostro caso abbiamo deciso di controllare la loss sulla validation\n",
    "- **min_delta** indica la variazione minima da rispettare, nel nostro caso abbiamo detto che ci deve essere una variazione di almeno 0.001\n",
    "- **patience** indica il numero di epoche su cui controllare il valore di min_delta\n",
    "- **mode** indica che cosa stiamo facendo con il valore da monitorare, noi abbiamo indicato che vogliamo minimizzarlo\n",
    "- **restore_best_weights** ci chiede se vogliamo tornare o meno al peso migliore ottenuto durante il training\n",
    "- **start_from_epoch** chiede da quale epoca far iniziare il monitoraggio\n",
    "\n",
    "Il fatto di avere impostato min come mode fa si che la variazione debba essere sempre verso la minimizzazione, altimenti anche un peggioramento con un delta di almeno 0.001 andrebbe bene, cosa che non vogliamo.<br>\n",
    "Abbiamo deciso di impostare un'epoca di inizio perché abbiamo notato che altrimenti ci fermava troppo presto dato che con lr grande si verificavano delle variazioni di loss verso l'alto che ci facevano fermare l'addestramento troppo presto e in più perché non ci serve tanto per evitare overfitting ma per trovare un numero di epoche adatto per fermare l'addestramento quando non ci sono più miglioramenti per questo abbiamo deciso di far partire l'early stop quando stiamo addestrando con il lr più piccolo.<br>\n",
    "In più abbiamo deciso di mettere ripristinare il peso migliore perché se l'addestramento si ferma per mancanza di miglioramenti il peso migliore sarà comunque quello dell'ultima epoca, ma se l'addestramento si ferma perché la loss stava peggiorando non conviene più prendere il peso dell'ultima epoca ma quello della migliore del training.\n",
    "\n",
    "Altro vantaggio dell'Early Stop è quello di poter impostare un numero di epoche abbastanza alto in quanto l'addestramento si dovrebbe fermare prima, quindi quello di addestrare sul maggior numero di epoche possibili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9aebcc-f951-47c5-882d-ba2106895d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definiamo l'early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',         #guardo la loss di validazione\n",
    "    min_delta=0.001,            #serve un miglioramento almeno di 0.001\n",
    "    patience=3,                 #se per 3 epoche non migliora, mi fermo\n",
    "    mode='min',                 #voglio minimizzare la loss\n",
    "    restore_best_weights=True,  #torno ai pesi migliori\n",
    "    start_from_epoch=10         #epoca dalla quale partire con il monitoraggio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c767b-02cf-4b49-9d93-e7553b4c736e",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "Definiamo la nostra loss function<br>\n",
    "Si può anche usare la Cross Entropy e non la Focal, i risultati non cambiano di molto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610dcc3c-1ac7-4b4a-a318-1971a2facd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import CategoricalFocalCrossentropy\n",
    "from keras.optimizers import Nadam\n",
    "from keras.metrics import MeanIoU\n",
    "model.compile(\n",
    "    loss=CategoricalFocalCrossentropy(from_logits=True), #mettiamo True perché non abbiamo messo la softmax prima, questa scelta è migliore per questioni di arrotondamento sul calcolatore\n",
    "    optimizer=optimizer, #nadam è una variante della discesa lungo il gradiente stocastico\n",
    "    metrics=[MeanIoU(num_classes=2, sparse_y_true=False, sparse_y_pred=False),], #non usiamo l'accuracy per quanto detto in teoria\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff0ac2-964f-4945-a2bd-7242261c76ff",
   "metadata": {},
   "source": [
    "# Addestramento\n",
    "Di seguito addestriamo la rete specificando il train set, il validation set, il numero di epoche ed altri fattori tipo il verbose che permette di visualizzare una barra di progresso e la callback che ci permette di richiamare il nostro earlystop.<br>\n",
    "Si è deciso di impostare un numero di epoche pari a 30 ma si poteva mettere anche più alto, tanto la presenza dell'early stop ferma l'addestramento prima<br>\n",
    "Alla rete è stato assegnato un nome che ci tornarà utile nel passo successivo per poter disegnare i grafici<br>\n",
    "Dopo aver addestrato salviamo i pesi in un file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f787bf5-d967-4040-9696-959dec2f653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gruppo_2 = model.fit(train_ds, epochs=30, validation_data=valid_ds, verbose=True, callbacks=[early_stop])\n",
    "model.save_weights('gruppo_2.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060467ab-a348-47a9-bc07-8a0fc267bd90",
   "metadata": {},
   "source": [
    "# Visualizzazione grafica andamento loss\n",
    "Di seguito effettuiamo una visualizzazione grafica di come sta andando la loss e la loss sulla validation in modo da avere ad impatto grafico un'idea di quello che sta succedendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73770c90-0f8d-421a-b22c-760d5304e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoche = len(gruppo_2.history['loss']) #calcolo il numero di epoche come numero di valori di loss\n",
    "\n",
    "plt.plot(gruppo_2.history['loss'], label='Training loss') #plotta la curva della training loss\n",
    "plt.plot(gruppo_2.history['val_loss'], label='Validation loss') #plotta la curva della validation loss\n",
    "plt.xticks(np.arange(epoche)) #setta l'asse x con i valori del numero di epoche\n",
    "plt.xlabel('epochs') #rinomina l'asse x\n",
    "plt.ylabel('loss value') #rinomina l'asse y\n",
    "plt.title('Training vs Validation loss') #da un titolo al grafico\n",
    "plt.legend() #crea una legenda\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a97e3d",
   "metadata": {},
   "source": [
    "Visualizziamo anche l'andamento del valore di Mean IoU sia su train set sia su validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gruppo_2.history['mean_io_u'], label='Mean_io_u')\n",
    "plt.plot(gruppo_2.history['val_mean_io_u'], label='Validation Mean_io_u')\n",
    "plt.xticks(np.arange(epoche))\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Mean IoU value')\n",
    "plt.title('Training vs Validation Mean IoU')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53657d87-e850-444c-835e-850958df31ee",
   "metadata": {},
   "source": [
    "# Test rete\n",
    "Di seguito testiamo la rete e stampiamo le metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d0a3e-3293-4e87-b9ad-db5c930d3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test_ds, return_dict=True, verbose=True)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4712773-71b6-4a33-bf3d-7dffccbab745",
   "metadata": {},
   "source": [
    "# Visualizzazion del risultato\n",
    "Come avevamo fatto in precedenza anche qui visualizziamo un batch, in questo caso sarà presente anche la maschera predetta per poter fare un confronto visivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a69ad-a18c-4333-b7e2-e7ec9c0d0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizziamo il risultato\n",
    "from easy_cv_dataset.visualization import plot_segmentation_mask_gallery\n",
    "for images, segms in test_ds.take(1): #prendiamo il primo batch del testset\n",
    "    pred = model.predict(images) #lanciamo la rete sul singolo batch con il comando predict\n",
    "    plot_segmentation_mask_gallery(\n",
    "        images, y_true=segms, y_pred=pred, num_classes=num_classes\n",
    "    )\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0619d5-445a-4bbb-afe5-e92fbd48f475",
   "metadata": {},
   "source": [
    "# [Conteggio cellule](https://scikit-image.org/docs/0.25.x/api/skimage.measure.html#skimage.measure.label)\n",
    "Di seguito contiamo le cellule presenti tramite la funzione label della libreria skimage.measure<br>\n",
    "Measure restituisce due cose, una matrice che è la maschera e il numero contato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d58edf-d8bd-425b-82f9-6501af9a04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label\n",
    "index = 2\n",
    "mask_pred, num_pred = label(pred[index,:,:,1]>0, background=None, return_num=True, connectivity=None)\n",
    "mask_true, num_true = label(segms[index,:,:,1]>0, background=None, return_num=True, connectivity=None)\n",
    "print('Cellule reali contate: ',num_true)\n",
    "print('Cellule predette contate: ',num_pred)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(mask_true, cmap='jet')\n",
    "plt.title('Maschera reale')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask_pred, cmap='jet')\n",
    "plt.title('Maschera predetta')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00466f66-197e-4938-b136-e832e4c4acb1",
   "metadata": {},
   "source": [
    "# [Identificazione cellule](https://scikit-image.org/docs/0.25.x/auto_examples/segmentation/plot_label.html)\n",
    "mpathes è una libreria che serve per disegnare forme, nel nostro caso rettangoli<br>\n",
    "label_image serve per etichettare le regioni<br>\n",
    "image_label_overlay colora ogni regione con un colore diverso e li sovrappone a mask_pred<br>\n",
    "Il ciclo for serve per avere una lista di oggetti per ogni regione<br>\n",
    "Vengono prese solo regioni di dimensione >= a 20<br>\n",
    "Si danno le coordinate del rettangolo da fare con rigion.bbox<br>\n",
    "rect disegna il rettangolo<br>\n",
    "Alla fine si nascondono gli assi, si sistemano i margini e si visualizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6bc96-bbf7-4d9e-9d8c-0db56e9f81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, footprint_rectangle\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "label_image = label(mask_pred)\n",
    "\n",
    "image_label_overlay = label2rgb(label_image, image=mask_pred, bg_label=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(image_label_overlay)\n",
    "\n",
    "for region in regionprops(label_image):\n",
    "    if region.area >= 20:\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle(\n",
    "            (minc, minr),\n",
    "            maxc - minc,\n",
    "            maxr - minr,\n",
    "            fill=False,\n",
    "            edgecolor='red',\n",
    "            linewidth=2,\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
